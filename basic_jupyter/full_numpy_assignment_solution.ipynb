{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual preamble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([2,3,1,0])\n",
    "y =np.arange(10)\n",
    "z = 2 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 1, 0]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([4, 5, 3, 2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write expressions in the next cell to retrieve 1 from `x`, 3 from `y`, and 3 from `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x[2])\n",
    "print(y[3])\n",
    "print(z[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, write an expression that generates a 5 by 5 array filled with zeros, and another  that generates a 1 by 1 array with a 1 in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_by_five = np.zeros((5,5))\n",
    "one_by_one = np.ones((1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    @font-face {\n",
    "        font-family: \"Computer Modern\";\n",
    "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
    "    }\n",
    "    div.cell{\n",
    "        width:800px;\n",
    "        margin-left:16% !important;\n",
    "        margin-right:auto;\n",
    "    }\n",
    "    h1 {\n",
    "        font-family: Helvetica, serif;\n",
    "    }\n",
    "    h4{\n",
    "        margin-top:12px;\n",
    "        margin-bottom: 3px;\n",
    "       }\n",
    "    div.text_cell_render{\n",
    "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
    "        line-height: 145%;\n",
    "        font-size: 130%;\n",
    "        width:800px;\n",
    "        margin-left:auto;\n",
    "        margin-right:auto;\n",
    "    }\n",
    "    .CodeMirror{\n",
    "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
    "    }\n",
    "    .text_cell_render h5 {\n",
    "        font-weight: 300;\n",
    "        font-size: 22pt;\n",
    "        color: #4057A1;\n",
    "        font-style: italic;\n",
    "        margin-bottom: .5em;\n",
    "        margin-top: 0.5em;\n",
    "        display: block;\n",
    "    }\n",
    "    \n",
    "    .warning{\n",
    "        color: rgb( 240, 20, 20 )\n",
    "        }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, write an expression that uses an assignment to a splice to make all the negative values in `a` be 0.  Attention: This can be done more easily in numpy than it can in normal Python.  See if you can do it the easy way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  6  5  4  3  2  1  0 -1 -2 -3]\n",
      "[7 6 5 4 3 2 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10,-1,-1) - 3\n",
    "print(a)\n",
    "a[-3:] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell write an expression that produces an array containing result of multiplying 7 by each of the first 12 integers (1 - 12). There's a hard way to do this and an easy way.  The easy way uses elementwise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * np.arange(1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "room_matrix = \\\n",
    "np.array(\n",
    "[[6,  3, 4, 1],\n",
    "[5,  2, 3, 2],\n",
    "[8,  3, 6, 2],\n",
    "[5,  1, 3, 1],\n",
    "[10, 4, 7, 2]])\n",
    "\n",
    "cost_vector = np.array([40, 175, 90, 450])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell write an express that retrieves the last column of `room_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_matrix[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, write an expression that retrieves the third row of `room_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 6, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_matrix[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell write an expression that retrieves the first two rows of the second column of `room_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_matrix[0:2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell write an expression that retrieves the following submatrix from `room_matrix`:\n",
    "\n",
    "```\n",
    "array([[2,3],\n",
    "       [3,6]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_matrix[1:3,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, write an expression that returns a Boolean array that identifies the members of `room_matrix` which are greater than or equal to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [ True, False,  True, False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_matrix >= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris data exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use a Boolean mask to return all the rows of the iris data set whose column 3 value is greater than 1.8 (I mean the column whose **index** is 3, the last column).\n",
    "The cell is not empty because you have been provided with the code which loads the data.\n",
    "So you should keep that code and **add to it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "features = data['data']\n",
    "target = data['target']\n",
    "features[features[:,3]>1.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use a Boolean mask to return all the members of class 2 in the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features[target == 2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit:  In the next cell write an expression -- or expressions -- which returns\n",
    "all the members of class 2 in the data whose column 3 value is greater than 1.8.\n",
    "\n",
    "Hint: Set a variable to store the result of one of your answers to the last two questions.\n",
    "That result is an array, and you can do more indexing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls2 = features[target == 2,:]\n",
    "cls2[cls2[:,3]>1.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it doesn't work to do this in the other order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gawron/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/ipykernel/__main__.py:2: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 34 but corresponding boolean dimension is 150\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 34",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-77db99cde48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlarge_col_three\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlarge_col_three\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 34"
     ]
    }
   ],
   "source": [
    "large_col_three = features[features[:,3]>1.8]\n",
    "large_col_three[target==2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the Boolean array used for indexing must be exactly the same length as the array indexed:\n",
    "\n",
    "```\n",
    "indexed[indexing == 'something']\n",
    "```\n",
    "`indexing == 'something'` needs to return an array of Booleans of exactly the same length\n",
    "as `indexed`.  For that to happen, `indexing` has to be the same length as `indexed`.\n",
    "This is analogous to the constraint on elementwise arithmetic between\n",
    "arrays. If you add or multiply two arrays `X` and `Y`, they need to be the same length,\n",
    "too.  The array `target` is the same length as `features`, so\n",
    "\n",
    "```\n",
    "features[target==2,:]\n",
    "```\n",
    "works. You get back the rows of `features` that correspond to a `True` in the Boolean vector\n",
    "`target == 2`.  But when you do\n",
    "\n",
    "```\n",
    "large_col_three = features[features[:,3]>1.8]\n",
    "```\n",
    "\n",
    "you get an array of reduced size, which is no longer the same length as `target`.\n",
    "Hence\n",
    "\n",
    "```\n",
    "large_col_three[target==2,:]\n",
    "```\n",
    "\n",
    "raises an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston data exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "X,Y = boston.data,boston.target\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The cell above loads the `sklearn` Boston housing data, which contains information about housing prices\n",
    "for 501 houses sold in Boston, and the values of various attributes which have been found to be useful\n",
    "in predicting home prices:\n",
    "\n",
    "```\n",
    "Index\n",
    "0         - CRIM     per capita crime rate by town\n",
    "1         - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "2         - INDUS    proportion of non-retail business acres per town\n",
    "3         - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "4         - NOX      nitric oxides concentration (parts per 10 million)\n",
    "5         - RM       average number of rooms per dwelling\n",
    "6         - AGE      proportion of owner-occupied units built prior to 1940\n",
    "7         - DIS      weighted distances to five Boston employment centres\n",
    "8         - RAD      index of accessibility to radial highways\n",
    "9         - TAX      full-value property-tax rate per $10,000\n",
    "10        - PTRATIO  pupil-teacher ratio by town\n",
    "11        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "12        - LSTAT    % lower status of the population\n",
    "```\n",
    "\n",
    "The array `X`, defined in the cell above, is a 501x13 array containing the values of all\n",
    "these variables for 501 Boston houses.  \n",
    "\n",
    "The information stored in Y, the value to be predicted is\n",
    "\n",
    "```\n",
    "       - MEDV     Median value of owner-occupied homes in $1000's\n",
    " \n",
    "```\n",
    "\n",
    "1.  Construct an expression or expressions that creates a new table that omits all houses whose tracts\n",
    "    bound the Charles River.\n",
    "2.  Construct an expression or expressions that creates a new table containing only the CRIM column and\n",
    "    the ZN column.  This is  our new X.  Also craete a new Y containing the pupil-teach ratio.  \n",
    "    This is to help someone research how to predict poor education conditions.  The shape of the new X should\n",
    "    (506,2) and the shape of the new Y should be (506,).  Show that you checked this in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[:,3]==0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NewX = X[X[:,3]==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(471, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(NewX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 2), (506,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewX = X[:,0:2]\n",
    "NewY = X[:,10]\n",
    "NewX.shape, NewY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using numpy arrays for frequency data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we build a 2D array representing a textual data set. There are tools that will do what we doing here much faster than the code you write, but the idea is for you to gain a better understanding of what the actual computational representation of the data is by building it yourself.\n",
    "\n",
    "Steps\n",
    "\n",
    "1.  We loop through a set of documents getting the vocab counts for each.  Our final vocabulary is the union of the vocabularies of the documents, i.e., every word we've seen in the data set, even if it occurred in only one document.\n",
    "2. Let D be the number of documents.  Let V be the vocab size.  We build a DxV matrix M representing the frequency counts of each word in each document.  `M[i,j]` is the count of the `j`-th word in the `i`-th document.\n",
    "\n",
    "The matrix M can be passed directly to a machine learning algorithm as its training matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('austen/{0}.txt'.format('northanger_abbey'),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from collections import Counter\n",
    "\n",
    "docset = ['pride_and_prejudice','northanger_abbey',\n",
    "          'emma', 'mansfield_park',\n",
    "          'sense_and_sensibility', 'persuasion']\n",
    "vocab = set()\n",
    "doc_counts = []\n",
    "for d in docset:\n",
    "    with open('austen/{0}.txt'.format(d),'r') as fh:\n",
    "        ctr = Counter(fh.read().lower().split())\n",
    "        vocab.update(list(ctr.keys()))\n",
    "        doc_counts.append(ctr)\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "(D,V) = (len(doc_counts), len(vocab))\n",
    "\n",
    "M = np.zeros((D,V))\n",
    "for i in range(D):\n",
    "    doc_ctr_i = doc_counts[i]\n",
    "    for j in range(V):\n",
    "        M[i,j] = doc_ctr_i[vocab[j]]\n",
    "\n",
    "# The words counts for each document.\n",
    "# A vector of length 6. Applying norm\n",
    "# function to rows, M[0,:], M[1,:], M[2,:], etc., \n",
    "# i.e., slices along dimension 1\n",
    "doc_sizes = LA.norm(M,ord=1,axis=1)\n",
    "\n",
    "#def divide (x,y):\n",
    "#    return x/y\n",
    "\n",
    "# Divide every word count in a doc by the doc size of the doc\n",
    "# Divide each column vector [a vector of length 6] elementwise\n",
    "# by doc_sizes [another vector of length 6].\n",
    "# We are applying the function to columns, \n",
    "# M[:,0],M[:,1,],M[:,2], etc., i.e., slices along dimension, 0.\n",
    "M_norm = np.apply_along_axis(np.divide,0,M,doc_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the `apply_along_axis` function.  The basic idea is to apply any function of a 1D array, to either rows or columns of a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def my_average(a):\n",
    "    \"\"\"Find size of average element of a 1-D array\"\"\"\n",
    "    return sum(a)/float(len(a))\n",
    "\n",
    "# a 3x3 array.\n",
    "#X = np.array([[1,2,3,4,5], [4,5,6,7,8], [7,8,9,10,11]])\n",
    "X = np.array([[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis 0, apply my_average to 5 cols of X [  6.   7.   8.   9.  10.]\n",
      "Axis 1, apply my_average to to 3 rows of X [  3.   8.  13.]\n"
     ]
    }
   ],
   "source": [
    "print('Axis 0, apply my_average to 5 cols of X',np.apply_along_axis(my_average, 0, X))\n",
    "print('Axis 1, apply my_average to to 3 rows of X',np.apply_along_axis(my_average, 1, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing `M_norm` above, we gave `apply_along_axis` one more argument `doc_sizes` which is interpreted as an additional argument of `np.divide`, so this means we divide every column elementwise by the document sizes vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `M` gives the counts for a word in a document, and `M_norm` the proportion of the document the word occupies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 39548) (6, 39548)\n",
      "1 northanger_abbey\n",
      "0 pride_and_prejudice\n",
      "34915 the\n",
      "3321.0 0.0414327419717\n",
      "4479.0 0.0359504928243\n"
     ]
    }
   ],
   "source": [
    "print(M.shape, M_norm.shape)\n",
    "print(docset.index('northanger_abbey'), docset[1])\n",
    "print(docset.index('pride_and_prejudice'),docset[0])\n",
    "print(vocab.index('the'),vocab[34915])\n",
    "\n",
    "print(M[1,34915], M_norm[1,34915])\n",
    "print(M[0,34915], M_norm[0,34915])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the code above carefully, make sure you understand it. Answer the following questions about `M` and `M_norm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  What is the size of Jane Austen's vocabulary?  How many words long is the Jane Austen canon (the sum of the lengths [in words] of the 6 novels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 39548\n",
      "Size of canon 735640.0\n"
     ]
    }
   ],
   "source": [
    "print('Vocab size', len(vocab))\n",
    "print('Size of canon', saum(doc_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 124588.,   80154.,  160449.,  162553.,  121590.,   86306.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, she has not passed the million word milestone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  How many times does \"time\" occur in *Pride and Prejudice*?  Show the computations you use to compute this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35427\n",
      "0\n",
      "Count of \"time\" in \"Pride and Prejudice\": 136.0\n"
     ]
    }
   ],
   "source": [
    "time_index = vocab.index('time')\n",
    "pride_and_prejudice_index = docset.index('pride_and_prejudice')\n",
    "print(time_index)\n",
    "print(pride_and_prejudice_index) \n",
    "print('Count of \"time\" in \"Pride and Prejudice\":',M[pride_and_prejudice_index,time_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)  How many times does \"year\" occur in *Sense and Sensibility*?  Show your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39291\n",
      "4\n",
      "Count of \"year\" in \"Sense and Sensibility\": 14.0\n"
     ]
    }
   ],
   "source": [
    "year_index = vocab.index('year')\n",
    "sense_and_sensibility_index = docset.index('sense_and_sensibility')\n",
    "print(year_index)\n",
    "print(sense_and_sensibility_index)\n",
    "print('Count of \"year\" in \"Sense and Sensibility\":',M[sense_and_sensibility_index,year_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)  Note that 'It' is not present in the vocabulary.  Can we conclude that Jane Austen never starts a sentence with 'It'?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire string of each novel is lower cased before being passed to the counter for that novel:\n",
    "\n",
    "```\n",
    "ctr = Counter(fh.read().lower().split())\n",
    "```\n",
    "\n",
    "So we only know that the word `it` occurred, not whether it was lower or upper case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)  Compute an array which gives the counts for the word \"gentleman\" in all 6 Jane Austen novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18.,  20.,  14.,  10.,  18.,  12.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentleman_index = vocab.index('gentleman')\n",
    "M[:,gentleman_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one novel has 20 occurrences of `gentleman` in the count vector above.  That is the novel with index 1. To see which one that is, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'northanger_abbey'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In two lines of code this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'northanger_abbey'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentleman_counts = list(M[:,gentleman_index])\n",
    "docset[gentleman_counts.index(max(gentleman_counts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)  Which novel has the largest number of tokens of \"truth\"?  Show your computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emma'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_index = vocab.index('truth')\n",
    "truth_counts = list(M[:,truth_index])\n",
    "docset[truth_counts.index(max(truth_counts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)  Which novel has the largest proportion of occurrences of \"lady\" and which the largest proportion of occurrences of \"gentleman\"?  Which word shows up more often in Austen's writings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest proportion of tokens of \"lady\": persuasion\n"
     ]
    }
   ],
   "source": [
    "lady_index = vocab.index('lady')\n",
    "lady_props = list(M_norm[:,lady_index])\n",
    "print('Greatest proportion of tokens of \"lady\":', docset[lady_props.index(max(lady_props))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest proportion of tokens of \"gentleman\": northanger_abbey\n"
     ]
    }
   ],
   "source": [
    "gentleman_index = vocab.index('gentleman')\n",
    "gentleman_counts = list(M_norm[:,gentleman_index])\n",
    "print('Greatest proportion of tokens of \"gentleman\":', docset[gentleman_counts.index(max(gentleman_counts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counts  \"lady\" 716.0\n",
      "Total counts  \"gentleman\" 92.0\n"
     ]
    }
   ],
   "source": [
    "lady_index = vocab.index('lady')\n",
    "gentleman_index = vocab.index('gentleman')\n",
    "total_lady_counts = sum(M[:,lady_index])\n",
    "total_gentleman_counts = sum(M[:,gentleman_index])\n",
    "print('Total counts  \"lady\"', total_lady_counts)\n",
    "print('Total counts  \"gentleman\"', total_gentleman_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It's not even close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 166.   27.   32.  169.  122.  200.]\n",
      "[ 18.  20.  14.  10.  18.  12.]\n"
     ]
    }
   ],
   "source": [
    "print(M[:,lady_index])\n",
    "print(M[:,gentleman_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Northanger Abbey* and *Emma* are the outliers for *lady*.\n",
    "\n",
    "Temporal order:\n",
    "\n",
    "1. Sense and Sensibility\n",
    "2. Pride and Prejudice\n",
    "3. Northanger Abbey\n",
    "4. Mansfield Park\n",
    "5. Emma\n",
    "6. Persuasion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "_merged",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
